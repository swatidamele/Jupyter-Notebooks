{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "ipy-jupyter-venv3",
      "language": "python",
      "name": "myipy_jupter_env3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "Copy of NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swatidamele/Jupyter-Notebooks/blob/main/Copy_of_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03e9758b"
      },
      "source": [
        "import pandas as pd\n",
        "from random import randrange\n",
        "import random"
      ],
      "id": "03e9758b",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0381161d"
      },
      "source": [
        "NEG = 0\n",
        "POS = 1\n",
        "ALL = 2"
      ],
      "id": "0381161d",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqDX26jyGIFW"
      },
      "source": [
        "**1. Take IMDB review text file as input data**"
      ],
      "id": "TqDX26jyGIFW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f459219",
        "outputId": "10f71263-d626-4c61-eddb-a9fc40993223"
      },
      "source": [
        "df=pd.read_csv(r\"https://raw.githubusercontent.com/swatidamele/Jupyter-Notebooks/main/imdb_labelled.txt\",delimiter=\"\\t\",header=None,names=[\"IMDB Review\",\"Sentiment\"])\n",
        "df.columns"
      ],
      "id": "4f459219",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['IMDB Review', 'Sentiment'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "b7d7f17e",
        "outputId": "904bbaff-28ea-4977-a7fd-fd82ccd6ce91"
      },
      "source": [
        "df=df.replace(',','',regex=True).replace('!','',regex=True).replace('\\.','',regex=True).replace('-','',regex=True)\n",
        "df   "
      ],
      "id": "b7d7f17e",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IMDB Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very very very slowmoving aimless movie abou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost  the flat character...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>I just got bored watching Jessice Lange take h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>Unfortunately any virtue in this film's produc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>In a word it is embarrassing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>Exceptionally bad</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>All in all its an insult to one's intelligence...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>748 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           IMDB Review  Sentiment\n",
              "0    A very very very slowmoving aimless movie abou...          0\n",
              "1    Not sure who was more lost  the flat character...          0\n",
              "2    Attempting artiness with black & white and cle...          0\n",
              "3          Very little music or anything to speak of            0\n",
              "4    The best scene in the movie was when Gerardo i...          1\n",
              "..                                                 ...        ...\n",
              "743  I just got bored watching Jessice Lange take h...          0\n",
              "744  Unfortunately any virtue in this film's produc...          0\n",
              "745                     In a word it is embarrassing            0\n",
              "746                                Exceptionally bad            0\n",
              "747  All in all its an insult to one's intelligence...          0\n",
              "\n",
              "[748 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRu_iny3Bq7t"
      },
      "source": [
        "**2. Divide the dataset as train, development and test**\n"
      ],
      "id": "sRu_iny3Bq7t"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff779bef",
        "outputId": "2d8cc1bc-d0e6-4b11-d644-9216aed93033"
      },
      "source": [
        "split_1 = int(0.8 * len(df))\n",
        "split_2 = int(0.9 * len(df))\n",
        "train_data = df[:split_1]\n",
        "dev_data = df[split_1:split_2]\n",
        "test_data = df[split_2:]\n",
        "print(\"Train Data\")\n",
        "print((train_data))\n",
        "print(\"Dev Data\")\n",
        "print((dev_data))\n",
        "print(\"Test Data\")\n",
        "print((test_data))"
      ],
      "id": "ff779bef",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data\n",
            "                                           IMDB Review  Sentiment\n",
            "0    A very very very slowmoving aimless movie abou...          0\n",
            "1    Not sure who was more lost  the flat character...          0\n",
            "2    Attempting artiness with black & white and cle...          0\n",
            "3          Very little music or anything to speak of            0\n",
            "4    The best scene in the movie was when Gerardo i...          1\n",
            "..                                                 ...        ...\n",
            "593  This film highlights the fundamental flaws of ...          1\n",
            "594  The film is well paced understated and one of ...          1\n",
            "595  This mostly routine factbased TV drama gets a ...          1\n",
            "596                  Predictable but not a bad watch            1\n",
            "597  It was clear that she had the range and abilit...          1\n",
            "\n",
            "[598 rows x 2 columns]\n",
            "Dev Data\n",
            "                                           IMDB Review  Sentiment\n",
            "598                       She carries the movie well            1\n",
            "599  Constantine gives everything the right intensi...          1\n",
            "600  It is wonderful and inspiring to watch and I h...          1\n",
            "601  How this piece of trash was ever released is b...          0\n",
            "602  In fact this stinker smells like a directtovid...          0\n",
            "..                                                 ...        ...\n",
            "668            The story line is totally predictable            0\n",
            "669  Not much dialogue not much music the whole fil...          1\n",
            "670  I've seen soap operas more intelligent than th...          0\n",
            "671          Bad characters bad story and bad acting            0\n",
            "672                                     Really awful            0\n",
            "\n",
            "[75 rows x 2 columns]\n",
            "Test Data\n",
            "                                           IMDB Review  Sentiment\n",
            "673                                Not easy to watch            0\n",
            "674  Funny clever hip  just like Pray's previous fi...          1\n",
            "675  It was a long time that i didn't see a so char...          1\n",
            "676  Paolo Sorrentino has written a wonderful story...          1\n",
            "677  The movie is not completely perfect but 'Titta...          1\n",
            "..                                                 ...        ...\n",
            "743  I just got bored watching Jessice Lange take h...          0\n",
            "744  Unfortunately any virtue in this film's produc...          0\n",
            "745                     In a word it is embarrassing            0\n",
            "746                                Exceptionally bad            0\n",
            "747  All in all its an insult to one's intelligence...          0\n",
            "\n",
            "[75 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ef91630"
      },
      "source": [
        "validation_data=train_data.values.tolist()\n",
        "dev_data_values=dev_data.values.tolist()\n",
        "test_data_values=test_data.values.tolist()"
      ],
      "id": "7ef91630",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0INv9c5LG5m"
      },
      "source": [
        "**3. Take the count of statements based on sentiment**"
      ],
      "id": "D0INv9c5LG5m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "975391de"
      },
      "source": [
        "def count_sentence(data):\n",
        "    label_count=[0,0, len(data)] # [neg_count, pos_count, all_count]\n",
        "    for item in data:\n",
        "        #label_count[ALL]+=1\n",
        "        if item[1]== 0:\n",
        "            label_count[NEG]+=1\n",
        "        else:\n",
        "            label_count[POS]+=1\n",
        "            \n",
        "    return label_count"
      ],
      "id": "975391de",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ce0456d",
        "outputId": "16a2ca82-5d4f-4442-d347-d2e238c10060"
      },
      "source": [
        "total_count = count_sentence(validation_data)\n",
        "print(\"Count of sentences [Negative,Positive,All] is \",total_count)"
      ],
      "id": "0ce0456d",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of sentences [Negative,Positive,All] is  [313, 285, 598]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqombe48BlSJ"
      },
      "source": [
        "**4. Build a vocabulary as list and omit rare words if the occurrence is less than five times**\n"
      ],
      "id": "uqombe48BlSJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bsfm1rkCHfj"
      },
      "source": [
        "def word_vocabulary(data,threshold):\n",
        "   \n",
        "    vocab={}\n",
        "    \n",
        "    for sent in data:\n",
        "        count=0\n",
        "        for content in sent:\n",
        "            if(count%2==0): \n",
        "                word_list = content.split()\n",
        "                for word in word_list:\n",
        "                    if word.lower() not in vocab:\n",
        "                        vocab[word.lower()]=[0,0,0]\n",
        "                    else:\n",
        "                        vocab[word.lower()][ALL]+=1\n",
        "                        if(sent[count+1]==1):\n",
        "                            vocab[word.lower()][POS]+=1\n",
        "                        else:\n",
        "                            if(sent[count+1]==0):\n",
        "                                vocab[word.lower()][NEG]+=1\n",
        "                count+=1\n",
        "                    \n",
        "    for key in list(vocab.keys()):\n",
        "        if vocab[key][ALL]<threshold:\n",
        "            del vocab[key]\n",
        "                      \n",
        "    return(vocab)"
      ],
      "id": "3Bsfm1rkCHfj",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a8ecb82",
        "outputId": "5776455c-fd31-402a-b1ee-0892c934898e"
      },
      "source": [
        "Dict = word_vocabulary(validation_data,5)\n",
        "df_dict = pd.DataFrame(list(Dict.items()),columns = ['Word','Count [Negative,Positive,All]']) \n",
        "print(df_dict)"
      ],
      "id": "4a8ecb82",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Word Count [Negative,Positive,All]\n",
            "0         a               [181, 156, 337]\n",
            "1      very                  [34, 25, 59]\n",
            "2     movie                 [82, 59, 141]\n",
            "3     about                  [22, 14, 36]\n",
            "4       man                     [4, 5, 9]\n",
            "..      ...                           ...\n",
            "258      am                     [6, 1, 7]\n",
            "259  seeing                     [2, 3, 5]\n",
            "260    each                     [2, 3, 5]\n",
            "261   makes                     [1, 5, 6]\n",
            "262  second                     [4, 1, 5]\n",
            "\n",
            "[263 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk5eGezECZT0"
      },
      "source": [
        "**5. Calculate the probability of the occurrence**\n"
      ],
      "id": "Nk5eGezECZT0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dac104b",
        "outputId": "ac7afe11-de6d-4051-dc21-effe3e9635c9"
      },
      "source": [
        "P_word = {}\n",
        "\n",
        "for word in Dict:\n",
        "    word_count = int(Dict[word][ALL])\n",
        "    total_all = total_count[ALL]\n",
        "    P = word_count/total_all\n",
        "    P_word[word] = P\n",
        "df_p_word = pd.DataFrame(list(P_word.items()),columns = ['Word','Probability(Word)'])     \n",
        "print(df_p_word) "
      ],
      "id": "9dac104b",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Word  Probability(Word)\n",
            "0         a           0.563545\n",
            "1      very           0.098662\n",
            "2     movie           0.235786\n",
            "3     about           0.060201\n",
            "4       man           0.015050\n",
            "..      ...                ...\n",
            "258      am           0.011706\n",
            "259  seeing           0.008361\n",
            "260    each           0.008361\n",
            "261   makes           0.010033\n",
            "262  second           0.008361\n",
            "\n",
            "[263 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G63eLbLBClkr"
      },
      "source": [
        "**6. Calculate the conditional probability based on the sentiment**"
      ],
      "id": "G63eLbLBClkr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0796e77b",
        "outputId": "a8db2f51-22f8-4eff-a15b-655a300283f9"
      },
      "source": [
        "P_conditional_pos_word = {}\n",
        "\n",
        "for word in Dict:\n",
        "    word_count = int(Dict[word][POS])\n",
        "    total = total_count[POS]\n",
        "    P = word_count/total\n",
        "    P_conditional_pos_word[word.lower()] = P\n",
        "df_p_conditional_pos_word = pd.DataFrame(list(P_conditional_pos_word.items()),columns = ['Word','Probability(Word|Positive)'])      \n",
        "print(df_p_conditional_pos_word)            "
      ],
      "id": "0796e77b",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Word  Probability(Word|Positive)\n",
            "0         a                    0.547368\n",
            "1      very                    0.087719\n",
            "2     movie                    0.207018\n",
            "3     about                    0.049123\n",
            "4       man                    0.017544\n",
            "..      ...                         ...\n",
            "258      am                    0.003509\n",
            "259  seeing                    0.010526\n",
            "260    each                    0.010526\n",
            "261   makes                    0.017544\n",
            "262  second                    0.003509\n",
            "\n",
            "[263 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "288e3cca",
        "outputId": "43987568-b741-4bc3-dd1c-5c549d5f13ff"
      },
      "source": [
        "P_conditional_neg_word = {}\n",
        "\n",
        "for word in Dict:\n",
        "    word_count_n = int(Dict[word][NEG])\n",
        "    total_n = total_count[NEG]\n",
        "    P_n = word_count_n/total_n\n",
        "    P_conditional_neg_word[word.lower()] = P_n\n",
        "df_p_conditional_neg_word = pd.DataFrame(list(P_conditional_pos_word.items()),columns = ['Word','Probability(Word|Negative)'])     \n",
        "print(df_p_conditional_neg_word)         "
      ],
      "id": "288e3cca",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Word  Probability(Word|Negative)\n",
            "0         a                    0.547368\n",
            "1      very                    0.087719\n",
            "2     movie                    0.207018\n",
            "3     about                    0.049123\n",
            "4       man                    0.017544\n",
            "..      ...                         ...\n",
            "258      am                    0.003509\n",
            "259  seeing                    0.010526\n",
            "260    each                    0.010526\n",
            "261   makes                    0.017544\n",
            "262  second                    0.003509\n",
            "\n",
            "[263 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATmJF5rOC0rZ"
      },
      "source": [
        "**7. Calculate accuracy using five fold cross validation and compare the effect of Smoothing**"
      ],
      "id": "ATmJF5rOC0rZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dad2efc1"
      },
      "source": [
        "\n",
        "k=5\n",
        "\n",
        "folds=validation_data \n",
        "#print(validation_data)\n",
        "fold_size= int((len(validation_data))/5)\n",
        "#print(fold_size)\n",
        "# for j in range(k):\n",
        "#     fold=[]\n",
        "#     for i in range(fold_size):\n",
        "#         random_index=randrange(50)\n",
        "#         if len(validation_data)>0:\n",
        "#             #print(validation_data[random_index][0])\n",
        "#             fold.append(validation_data[random_index][0])\n",
        "#             #fold.append(random.choice(validation_data))\n",
        "#             #print(fold)\n",
        "#             #fold.append(newData_validate.pop(random_index))\n",
        "#             #print(i)\n",
        "#     folds.append(fold)\n",
        "#     #print(folds)\n",
        "\n",
        "train_fold = folds[:450]\n",
        "test_fold = folds[450:]\n",
        "\n",
        "\n",
        "\n",
        "# fold_count = 0    \n",
        "# for fold in folds:\n",
        "#     if(fold_count == 4):\n",
        "#         test_fold = fold\n",
        "#     else:\n",
        "#         train_fold = train_fold + fold\n",
        "#     fold_count+=1\n",
        "    #train_fold = folds\n",
        "    #train_fold.remove(fold)\n",
        "    #train_fold = sum(train_fold, [])\n",
        "    #test_fold = fold\n",
        "#print(train_fold)\n",
        "   \n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "dad2efc1",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00961572"
      },
      "source": [
        "def predicted_sentiment(review, vocabulary, label_count, lam):\n",
        "\n",
        "    probability = []\n",
        "\n",
        "    for label in[0,1]:\n",
        "        prob = 1.0\n",
        "        counter = 0\n",
        "        for row in review:\n",
        "            if(counter%2==0):\n",
        "                sentarray = row.lower().split()\n",
        "                for word in sentarray:\n",
        "                    if word not in vocabulary:\n",
        "                        continue\n",
        "                    if lam == 0 and vocabulary[word][label]==0:\n",
        "                        prob = 0\n",
        "                        break\n",
        "                    prob = round(prob*((vocabulary[word][label]+lam) / (label_count[label]+(lam*len(vocabulary)))),5)        \n",
        "                counter+=1       \n",
        "        probability.append(prob)  \n",
        "    return 0 if probability[NEG]>probability[POS] else 1\n",
        "   "
      ],
      "id": "00961572",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee77582d",
        "outputId": "ec8af3ff-0c98-4072-e6f0-14fc18e4726b"
      },
      "source": [
        "l = [0,1]  \n",
        "\n",
        "occurrence_shreshold = 5\n",
        "\n",
        "new_train_fold = []\n",
        "\n",
        "voca = word_vocabulary(train_fold, occurrence_shreshold)\n",
        "\n",
        "label_count = count_sentence(train_fold)\n",
        "\n",
        "for lam in l:\n",
        "    accuracy = []\n",
        "    correct = 0\n",
        "    for review in test_fold:\n",
        "        flag1 = predicted_sentiment(review, voca, label_count, lam)\n",
        "        flag2 = int(review[1])\n",
        "        if(flag1 == flag2):\n",
        "            correct+=1\n",
        "    accuracy.append(correct/len(test_fold))\n",
        "    if(lam==0):\n",
        "        print(\"5-folds accuracy without smoothing is : \",accuracy)\n",
        "    else:\n",
        "        print(\"\\n5-folds accuracy with smoothing is : \",accuracy)"
      ],
      "id": "ee77582d",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5-folds accuracy without smoothing is :  [0.5540540540540541]\n",
            "\n",
            "5-folds accuracy with smoothing is :  [0.5945945945945946]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTeLzdTbDCQy"
      },
      "source": [
        "**8. Derive Top 10 words that predict positive and negative class**\n"
      ],
      "id": "jTeLzdTbDCQy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d29104e1"
      },
      "source": [
        "def prob_sentence(data,word,senti):\n",
        "    countarr=count_sentence(data)\n",
        "    finalarr=[]\n",
        "    count=0\n",
        "    count_conditional=0\n",
        "    if(senti==0):\n",
        "        count=countarr[1]\n",
        "        snt = 0\n",
        "    else:\n",
        "        count=countarr[0]\n",
        "        snt = 1\n",
        "    \n",
        "    #print(count)\n",
        "    for row in data:\n",
        "        if(row[1]==snt):\n",
        "            sentencearr=row[0].lower().split()\n",
        "            if word.lower() in sentencearr:\n",
        "                count_conditional+=1\n",
        "    finalarr.append(count_conditional)\n",
        "    finalarr.append(countarr[0])\n",
        "    finalarr.append(countarr[1])\n",
        "    if(senti==0):\n",
        "        cond_prob=count_conditional/countarr[0]\n",
        "    else:\n",
        "        cond_prob=count_conditional/countarr[1]\n",
        "    #print(cond_prob)    \n",
        "    return(cond_prob)"
      ],
      "id": "d29104e1",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d783ce9"
      },
      "source": [
        "vocabulary = word_vocabulary(validation_data, 5)\n",
        "label_count = count_sentence(validation_data)\n",
        "\n",
        "word_predict = {}\n",
        "\n",
        "for row in validation_data:\n",
        "  for word in row[0].split():             \n",
        "    if word not in vocabulary:\n",
        "      continue\n",
        "    neg_prob = (prob_sentence(validation_data,word,NEG) * (label_count[NEG]/label_count[ALL]))/ P_word[word]\n",
        "    pos_prob = (prob_sentence(validation_data,word,POS) * (label_count[POS]/label_count[ALL]))/ P_word[word]\n",
        "    pred = NEG if neg_prob > pos_prob else POS\n",
        "    if word not in word_predict:\n",
        "      word_predict[word] = [0,0,0]\n",
        "    word_predict[word][ALL] += 1\n",
        "    if pred == int(row[1]):  \n",
        "      word_predict[word][pred] += 1\n",
        "            \n",
        "top_neg_lst = sorted(word_predict, key = lambda x: word_predict[x][NEG]/word_predict[x][ALL], reverse=True) [:10]\n",
        "top_pos_lst = sorted(word_predict, key = lambda x: word_predict[x][POS]/word_predict[x][ALL], reverse=True)[:10]\n",
        "finalarr=[]\n",
        "finalarr.append(top_neg_lst)\n",
        "finalarr.append(top_pos_lst)"
      ],
      "id": "5d783ce9",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c00b5017",
        "outputId": "101742b0-c3f7-4b7e-fb9a-bcaab0c17877"
      },
      "source": [
        "arr = finalarr\n",
        "df_arr1 = pd.DataFrame(list(arr[0]),columns = ['Word']) \n",
        "print(\"Top 10 words that predict negative class are as follows: \\n\", arr[0])\n",
        "print(\"\\nTop 10 words that predict positive class are as follows: \\n\", arr[1])"
      ],
      "id": "c00b5017",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words that predict negative class are as follows: \n",
            " ['poor', 'lines', 'wasted', \"can't\", 'worst', 'annoying', 'these', 'dialogue', 'stupid', 'awful']\n",
            "\n",
            "Top 10 words that predict positive class are as follows: \n",
            " ['interesting', 'however', 'brilliant', 'wonderful', 'liked', 'actually', 'played', 'job', 'makes', 'family']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odmvvlgaDtox"
      },
      "source": [
        "**9. Use the optimal hyperparameters to calculate the final accuracy.**"
      ],
      "id": "odmvvlgaDtox"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ce00711"
      },
      "source": [
        "def fit(data,pos_lab,neg_lab):\n",
        "    predict_y=[]\n",
        "    for row in data:\n",
        "        probs1=[]\n",
        "        probs2=[]\n",
        "        for word in row[0].split():\n",
        "            if(word != \" \"):\n",
        "                t1=prob_sentence(data,word,0)\n",
        "                t2=prob_sentence(data,word,1)\n",
        "                probs1.append(t1)\n",
        "                probs2.append(t2)\n",
        "            prob1=1\n",
        "            prob2=1\n",
        "            for i in range(len(probs1)):\n",
        "                prob1= prob1*probs1[i]\n",
        "                prob2= prob2*probs2[i]\n",
        "            prob1=prob1*((neg_lab)/((pos_lab)+(neg_lab)))\n",
        "            prob2=prob2*((pos_lab)/((pos_lab)+(neg_lab)))\n",
        "            if(prob1>prob2):\n",
        "                predict_y.append(0)\n",
        "            else:\n",
        "                predict_y.append(1)\n",
        "    return predict_y  "
      ],
      "id": "0ce00711",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPFACnTjruYK"
      },
      "source": [
        "sentiarr=[]\n",
        "for row in test_data_values:\n",
        "    sentiarr.append(row[1])\n",
        "length=len(sentiarr)"
      ],
      "id": "MPFACnTjruYK",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fYhlu-wr0rQ"
      },
      "source": [
        "countarr=count_sentence(test_data_values)\n",
        "y_prediction=fit(test_data_values,countarr[0],countarr[1])\n",
        "y_prediction=(y_prediction[:length])"
      ],
      "id": "4fYhlu-wr0rQ",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wps8ddpxMVF2"
      },
      "source": [
        "count=0\n",
        "y_val = sentiarr\n",
        "for i in range(len(y_prediction)):\n",
        "   if(y_prediction[i]==int(y_val[i])):\n",
        "     count=count+1\n",
        "final_acc = count/len(y_val)  "
      ],
      "id": "Wps8ddpxMVF2",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ktkrwgr4XA",
        "outputId": "8d7756f7-f10c-4ccd-ffee-a1bcaab502dc"
      },
      "source": [
        "# final_acc=acc(y_prediction,sentiarr)  \n",
        "print(\"Final accuracy is : \",final_acc)  "
      ],
      "id": "H2ktkrwgr4XA",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final accuracy is :  0.72\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}